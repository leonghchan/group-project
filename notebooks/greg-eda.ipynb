{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "necessary-angle",
   "metadata": {},
   "source": [
    "### To dos\n",
    "- check skew of variables\n",
    "    - apply transformations as required\n",
    "- convert categoricals to dummy variables\n",
    "- deal with nulls/nans (or don't)\n",
    "- split off dependent/independent variables\n",
    "- scale/normalise\n",
    "- split into train/validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-batch",
   "metadata": {},
   "source": [
    "Let's start off with some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fewer-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-buffalo",
   "metadata": {},
   "source": [
    "We'll then load up the training data and derive a list of numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mental-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "numeric = [var for var in train.columns if train.dtypes[var] != 'object']\n",
    "category = [var for var in train.columns if train.dtypes[var] == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-player",
   "metadata": {},
   "source": [
    "Now let's analyse our null values, by feature type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "incident-starter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features with null values:\n",
      "LotFrontage    259\n",
      "GarageYrBlt     81\n",
      "MasVnrArea       8\n",
      "dtype: int64\n",
      "\n",
      "Categorical features with null values:\n",
      "PoolQC          1453\n",
      "MiscFeature     1406\n",
      "Alley           1369\n",
      "Fence           1179\n",
      "FireplaceQu      690\n",
      "GarageType        81\n",
      "GarageCond        81\n",
      "GarageQual        81\n",
      "GarageFinish      81\n",
      "BsmtFinType2      38\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtQual          37\n",
      "BsmtCond          37\n",
      "MasVnrType         8\n",
      "Electrical         1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "num_nulls = train[numeric].isnull().sum().sort_values(ascending=False)\n",
    "print(\"Numerical features with null values:\\n{}\".format(num_nulls[num_nulls > 0]))\n",
    "\n",
    "print()\n",
    "\n",
    "cat_nulls = train[category].isnull().sum().sort_values(ascending=False)\n",
    "print(\"Categorical features with null values:\\n{}\".format(cat_nulls[cat_nulls > 0]))\n",
    "\n",
    "\n",
    "# nulls = train.isnull().sum()\n",
    "# nulls = nulls[nulls > 0]\n",
    "# nulls = nulls.reset_index()\n",
    "# nulls.columns = ['variable', 'count']\n",
    "# nulls['percent'] = nulls['count'] / len(train)\n",
    "# nulls.sort_values(\"count\", ascending=False, inplace=True)\n",
    "# nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-concrete",
   "metadata": {},
   "source": [
    "Numerical features with null values should be replaceable with zeros. For the categoricals, we need to dig a little deeper.\n",
    "\n",
    "`PoolQC`, `MiscFeature`, `Alley`, `Fence`, and `FireplaceQu` all have ~50% or more missing values. Let's check in turn if we should drop the variable or convert it to a dummy.\n",
    "\n",
    "The `Garage*`, `Bsmt*`, and `MsnVnr*` variables each sharing the same values would indicate these nulls communicate an absence of that feature. We can capture this with a dummy variable which we create later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sweet-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'Ex' 'Fa' 'Gd']\n",
      "[nan 'Shed' 'Gar2' 'Othr' 'TenC']\n",
      "[nan 'Grvl' 'Pave']\n",
      "[nan 'MnPrv' 'GdWo' 'GdPrv' 'MnWw']\n",
      "[nan 'TA' 'Gd' 'Fa' 'Ex' 'Po']\n"
     ]
    }
   ],
   "source": [
    "high_null = [\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\"]\n",
    "for feat in high_null:\n",
    "    print(train[feat].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-timeline",
   "metadata": {},
   "source": [
    "In my estimation, `PoolQC` is probably covered adequately \n",
    "by the `PoolArea` feature; ditto `FireplaceQu` & `Fireplaces`; \n",
    "`MiscFeature`, with so many null values is unlikely to add value.\n",
    "\n",
    "We will delete these three, and convert the other two into \n",
    "dummy variables representing yes/no for 'has fence' and 'has alley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "assumed-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(train.columns) == 81:\n",
    "    train = train.drop(['PoolQC', 'MiscFeature', \"FireplaceQu\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-accreditation",
   "metadata": {},
   "source": [
    "Before we create our dummy variables, let's look at the last null value we haven't address: Electrical. Given that there is just one of entry, let's drop the data point with no electrical (how does that work anyway?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "signal-jacksonville",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1379    NaN\n",
      "Name: Electrical, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train[train[\"Electrical\"].isna() == True][\"Electrical\"])\n",
    "if len(train) == 1460:\n",
    "    train.drop(1379, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-zealand",
   "metadata": {},
   "source": [
    "Let's make those dummy variables. We will utilise the `pandas` built-in `get_dummies()`. Using this function, we capture natively the houses without garages, pools, etc. as entries with 0s for all the categorical options for a given variable. \n",
    "\n",
    "To address this on the numerical variable side, we will `fillna` with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "amber-screen",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PoolQC', 'FireplaceQu', 'MiscFeature'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a3aa0b21e528>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategoricals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnumericals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumericals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategoricals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PoolQC', 'FireplaceQu', 'MiscFeature'] not in index\""
     ]
    }
   ],
   "source": [
    "categoricals = pd.get_dummies(train[category])\n",
    "numericals = train[numeric].fillna(0)\n",
    "dataset = pd.merge(numericals, categoricals, left_index=True, right_index=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y = train['SalePrice'].sort_values()\n",
    "# # x = np.arange(len(y))\n",
    "# # fig, ax = plt.subplots(1,2)\n",
    "# # plt.figure(1); plt.title('Johnson SU')\n",
    "# # sns.displot(y)\n",
    "\n",
    "# number_of_bins = 50\n",
    "# bin_cutoffs = np.linspace(np.percentile(y,0), np.percentile(y,99),number_of_bins)\n",
    "# h = plt.hist(y, bins = bin_cutoffs, color='0.75')\n",
    "\n",
    "# # Create the plot\n",
    "# # sns.displot(y)\n",
    "# params = st.lognorm.fit(y)\n",
    "# # print(params)\n",
    "\n",
    "# fitted_pdf = st.lognorm.pdf(y, params[0], loc=params[-2], scale=params[-1])\n",
    "# scale_pdf = np.trapz(h[0], h[1][:-1]) / np.trapz(fitted_pdf, y)\n",
    "# fitted_pdf *= scale_pdf\n",
    "# # sns.lineplot(x=y, y=fitted_pdf)\n",
    "# plt.plot(y, fitted_pdf)\n",
    "# # sns.displot(y)\n",
    "# # plt.figure(2); plt.title('Normal')\n",
    "# # sns.distplot(y, kde=False, fit=st.norm)\n",
    "# # plt.figure(3); plt.title('Log Normal')\n",
    "# # sns.distplot(y, kde=False, fit=st.lognorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hazardous-priority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(train['SalePrice'], pd.core.frame.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "growing-copyright",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
